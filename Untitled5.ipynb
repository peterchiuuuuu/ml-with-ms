{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "#import PIL\n",
    "#import imageio\n",
    "#import pymol\n",
    "import csv\n",
    "#sys.path.insert(0, os.path.abspath('/Users/peterchiu/miniconda3/envs/my-rdkit-env/bin/'))\n",
    "#sys.path.append(\"/Users/peterchiu/miniconda3/envs/my-rdkit-env/bin/\")\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling2D, UpSampling2D, UpSampling1D, MaxPooling1D, Lambda, Reshape\n",
    "#from keras.layers import Conv1DTranspose\n",
    "##from keras.layers import Conv1DTranspose\n",
    "from rdkit import RDLogger  \n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.core import Dense, Flatten, RepeatVector, Dropout\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "#from tensorflow.nn import conv1d_transpose\n",
    "from keras import Sequential\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.nn_ops import conv1d_transpose\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_route = '/Users/peterchiu/Documents/data_analysis/QM9/'\n",
    "#dsgdb9nsd_000001.xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 34\n",
    "def add_space(raw_data, input_dim = 34):\n",
    "    out = []\n",
    "    for i in raw_data:\n",
    "        if len(i) < input_dim:\n",
    "            out.append(i+' '*(input_dim - len(i)))\n",
    "        else:\n",
    "            out.append(i)           \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SMILES_CHARS = [' ',\n",
    "                  '#', '%', '(', ')', '+', '-', '.', '/',\n",
    "                  '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                  '=', '@',\n",
    "                  'A', 'B', 'C', 'F', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P',\n",
    "                  'R', 'S', 'T', 'V', 'X', 'Z',\n",
    "                  '[', '\\\\', ']',\n",
    "                  'a', 'b', 'c', 'e', 'g', 'i', 'l', 'n', 'o', 'p', 'r', 's',\n",
    "                  't', 'u']\n",
    "'''\n",
    "SMILES_CHARS = [' ', 'C',\n",
    " 'N',\n",
    " 'O',\n",
    " '#',\n",
    " '=',\n",
    " '1',\n",
    " '(',\n",
    " ')',\n",
    " 'c',\n",
    " '[',\n",
    " 'n',\n",
    " 'H',\n",
    " ']',\n",
    " 'o',\n",
    " '3',\n",
    " '+',\n",
    " '-',\n",
    " '2',\n",
    " 'F',\n",
    " '4',\n",
    " '5']\n",
    "smi2index = dict( (c,i) for i,c in enumerate(SMILES_CHARS))\n",
    "index2smi = dict( (i,c) for i,c in enumerate(SMILES_CHARS))\n",
    "def smiles_encoder(smiles, maxlen=34):\n",
    "    #print(smiles)\n",
    "    #smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles))\n",
    "    #print(smiles)\n",
    "    X = np.zeros((maxlen, len(SMILES_CHARS)))\n",
    "    for i, c in enumerate(smiles):\n",
    "        #print(i)\n",
    "        #print(c)\n",
    "        X[i, smi2index[c]] = 1\n",
    "    return X\n",
    " \n",
    "def smiles_decoder( X ):\n",
    "    smi = ''\n",
    "    X = X.argmax( axis=-1 )\n",
    "    for i in X:\n",
    "        smi += index2smi[ i ]\n",
    "    return smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_raw = pd.read_csv('QM9_smiles.csv', header = None)[0]\n",
    "out = add_space(out_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9_properties = pd.read_csv('QM9_properties.csv') \n",
    "QM9_properties.columns = ['tag', 'index', 'A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo',\n",
    "'gap', 'r2', 'zpve', 'U0', 'U', 'H', 'G', 'Cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9_hot = []\n",
    "for i in out:\n",
    "    #print(i)\n",
    "    QM9_hot.append(smiles_encoder(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####calculate dis\n",
    "def dist_cal(latent_space_train, pos, dim = 156):\n",
    "    dist = (latent_space_train - pos)**dim\n",
    "    dist = np.sum(dist, axis=1)\n",
    "    dist = dist**(1/dim)\n",
    "    return(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_mse_loss(true, pred):\n",
    "    # Reconstruction loss\n",
    "    mse_loss = tf.keras.losses.MSE(K.flatten(true), K.flatten(pred))\n",
    "    #mse_loss = tf.keras.losses.MSE(true, pred)\n",
    "    #mse_loss = tf.keras.losses.MeanSquaredError(K.flatten(true), K.flatten(pred))\n",
    "    #reconstruction_loss = categorical_crossentropy(K.flatten(true), K.flatten(pred))\n",
    "    #reconstruction_loss *= 34*22\n",
    "    #* img_width * img_height\n",
    "    # KL divergence loss\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    #kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    # Total loss = 50% rec + 50% KL divergence loss\n",
    "    return K.mean(mse_loss + kl_loss)\n",
    "def kl_loss(true, pred):\n",
    "    kl = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl *= -0.5\n",
    "    return(kl)\n",
    "def mse_loss(true, pred):\n",
    "    #mse_loss = tf.keras.losses.MSE(true, pred)\n",
    "    mse_loss = tf.keras.losses.MSE(K.flatten(true), K.flatten(pred))\n",
    "    #mse_loss = tf.keras.losses.MeanSquaredError(K.flatten(true), K.flatten(pred), reduction=tf.keras.losses.Reduction.SUM)\n",
    "    #mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "    #mse(y_true, y_pred).numpy()\n",
    "    mse_loss *= 250\n",
    "\n",
    "    return(mse_loss)\n",
    "def reconstruct_error(true, pred):\n",
    "    reconstruct_error = binary_crossentropy(K.flatten(true), K.flatten(pred))\n",
    "    reconstruct_error *= 34*22\n",
    "    return(reconstruct_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:118: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "properties = keras.models.load_model(\"ep100_gap_valid_properties.h5\", custom_objects={'kl_mse_loss': kl_mse_loss, \n",
    "                                                           'kl_loss': kl_loss,\n",
    "                                        \n",
    "                                                                                          'mse_loss': mse_loss})\n",
    "def pp_prediction(x, model):\n",
    "    \n",
    "    return(model.predict(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.models.load_model(\"ep100_gap_valid_encoder.h5\", custom_objects={'kl_mse_loss': kl_mse_loss, \n",
    "                                                           'kl_loss': kl_loss,\n",
    "                                        \n",
    "                                                                                          'mse_loss': mse_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/peterchiu/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "decoder = keras.models.load_model(\"ep100_gap_valid_decoder.h5\", custom_objects={'kl_mse_loss': kl_mse_loss, \n",
    "                                                           'kl_loss': kl_loss,\n",
    "                                        \n",
    "                                                                                          'mse_loss': mse_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133885, 34, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = QM9_hot\n",
    "x_train = np.reshape(x_train, (len(x_train), 34, 22))\n",
    "y_train = QM9_properties['gap']\n",
    "y_train = np.reshape(y_train, (len(y_train)))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "laten_space = encoder.predict(x_train)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_m = decoder.predict(laten_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_st = []\n",
    "for i in decode_m:\n",
    "    predict_st.append(smiles_decoder(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1814094"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(max, laten_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.4367666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(map(min, laten_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampl = np.random.uniform(low=-5.4367666, high=6.1814094, size=(10,156)).reshape(-1,156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = decoder.predict(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_st = []\n",
    "for i in test:\n",
    "    predict_st.append(smiles_decoder(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid = 0\n",
    "oo = []\n",
    "for i, x in enumerate(predict_st):\n",
    "    #print(x)\n",
    "    m = Chem.MolFromSmiles(x, sanitize=False)\n",
    "    if m is None:\n",
    "        invalid += 1\n",
    "        oo.append('OOOOO')\n",
    "    else:\n",
    "        try:\n",
    "            oo.append(x)\n",
    "        except:\n",
    "            oo.append('XXXXX')\n",
    "            invalid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
